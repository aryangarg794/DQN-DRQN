{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Recurrent Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- https://arxiv.org/pdf/1507.06527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from gymnasium.wrappers import FrameStack\n",
    "from gymnasium.wrappers.frame_stack import LazyFrames\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    AtariWrapper,\n",
    "    FireResetEnv,\n",
    ")\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "from utils.replay import ReplayBuffer, make_env, LazyFramesToNumpyWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(frame, gray=False):\n",
    "    if gray:\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(game, render='rgb_array'):\n",
    "    env = gym.make(game, render_mode=render)\n",
    "    env = AtariWrapper(env, terminal_on_life_loss=False)\n",
    "    env = LazyFramesToNumpyWrapper(env)\n",
    "    if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = make_env('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observation, _ = env_test.reset()\n",
    "print(observation.shape)\n",
    "display_frame(observation, gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRQN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        env,\n",
    "        in_channels=1, \n",
    "        hidden_filters=list([32, 64, 64]),\n",
    "        hidden_size=512,\n",
    "        start_epsilon = 0.99,\n",
    "        max_decay = 0.1,\n",
    "        decay_steps = 1000, \n",
    "        device='cuda', \n",
    "        *args, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.env = env\n",
    "        self.start_epsilon = start_epsilon\n",
    "        self.epsilon = start_epsilon\n",
    "        self.max_decay = max_decay\n",
    "        self.decay_steps = decay_steps\n",
    "        self.num_actions = env.action_space.n\n",
    "        \n",
    "        self.layers_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_filters[0], kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_filters[0], hidden_filters[1], kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_filters[1], hidden_filters[2], kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_filters[-1] * 7 * 7, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, self.num_actions)\n",
    "        \n",
    "        self.apply(self._init)\n",
    "    \n",
    "    def forward(self, x, hidden_state, cell):\n",
    "        x = self.layers_cnn(x / 255.0)\n",
    "        x, hidden_state, cell = self.lstm(x, (hidden_state, cell))\n",
    "        \n",
    "        return ...\n",
    "        \n",
    "    def _init(self, m):\n",
    "      if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.zeros_(m.bias)\n",
    "              \n",
    "    def epsilon_greedy(self, state, dim=1):\n",
    "        rng = np.random.random()\n",
    "\n",
    "        if rng < self.epsilon:\n",
    "            action = self.env.action_space.sample()\n",
    "            action = torch.tensor(action)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self(state)\n",
    "            \n",
    "            action = torch.argmax(q_values, dim=dim)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def epsilon_decay(self, step):\n",
    "        self.epsilon = self.max_decay + (self.start_epsilon - self.max_decay) * max(0, (self.decay_steps - step) / self.decay_steps)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
